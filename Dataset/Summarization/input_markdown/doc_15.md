Migrating to astream\_events(..., version="v2") | ü¶úÔ∏èüîó LangChain[Skip to main content](#__docusaurus_skipToContent_fallback)[![](/img/brand/wordmark.png)![](/img/brand/wordmark-dark.png)](/)[Integrations](/docs/integrations/providers/)[API Reference](https://python.langchain.com/api_reference/)[More](#)

* [Contributing](/docs/contributing/)
* [People](/docs/people/)
* [Error reference](/docs/troubleshooting/errors/)
* ---
* [LangSmith](https://docs.smith.langchain.com)
* [LangGraph](https://langchain-ai.github.io/langgraph/)
* [LangChain Hub](https://smith.langchain.com/hub)
* [LangChain JS/TS](https://js.langchain.com)
[v0.3](#)

* [v0.3](/docs/introduction/)
* [v0.2](https://python.langchain.com/v0.2/docs/introduction)
* [v0.1](https://python.langchain.com/v0.1/docs/get_started/introduction)
[üí¨](https://chat.langchain.com)Search

* [Introduction](/docs/introduction/)
* [Tutorials](/docs/tutorials/)
  + [Build a Question Answering application over a Graph Database](/docs/tutorials/graph/)
  + [Tutorials](/docs/tutorials/)
  + [Build a simple LLM application with chat models and prompt templates](/docs/tutorials/llm_chain/)
  + [Build a Chatbot](/docs/tutorials/chatbot/)
  + [Build a Retrieval Augmented Generation (RAG) App: Part 2](/docs/tutorials/qa_chat_history/)
  + [Build an Extraction Chain](/docs/tutorials/extraction/)
  + [Build an Agent](/docs/tutorials/agents/)
  + [Tagging](/docs/tutorials/classification/)
  + [Build a Retrieval Augmented Generation (RAG) App: Part 1](/docs/tutorials/rag/)
  + [Build a semantic search engine](/docs/tutorials/retrievers/)
  + [Build a Question/Answering system over SQL data](/docs/tutorials/sql_qa/)
  + [Summarize Text](/docs/tutorials/summarization/)
* [How-to guides](/docs/how_to/)
  + [How-to guides](/docs/how_to/)
  + [How to use tools in a chain](/docs/how_to/tools_chain/)
  + [How to use a vectorstore as a retriever](/docs/how_to/vectorstore_retriever/)
  + [How to add memory to chatbots](/docs/how_to/chatbots_memory/)
  + [How to use example selectors](/docs/how_to/example_selectors/)
  + [How to add a semantic layer over graph database](/docs/how_to/graph_semantic/)
  + [How to invoke runnables in parallel](/docs/how_to/parallel/)
  + [How to stream chat model responses](/docs/how_to/chat_streaming/)
  + [How to add default invocation args to a Runnable](/docs/how_to/binding/)
  + [How to add retrieval to chatbots](/docs/how_to/chatbots_retrieval/)
  + [How to use few shot examples in chat models](/docs/how_to/few_shot_examples_chat/)
  + [How to do tool/function calling](/docs/how_to/function_calling/)
  + [How to install LangChain packages](/docs/how_to/installation/)
  + [How to add examples to the prompt for query analysis](/docs/how_to/query_few_shot/)
  + [How to use few shot examples](/docs/how_to/few_shot_examples/)
  + [How to run custom functions](/docs/how_to/functions/)
  + [How to use output parsers to parse an LLM response into structured format](/docs/how_to/output_parser_structured/)
  + [How to handle cases where no queries are generated](/docs/how_to/query_no_queries/)
  + [How to route between sub-chains](/docs/how_to/routing/)
  + [How to return structured data from a model](/docs/how_to/structured_output/)
  + [How to summarize text through parallelization](/docs/how_to/summarize_map_reduce/)
  + [How to summarize text through iterative refinement](/docs/how_to/summarize_refine/)
  + [How to summarize text in a single LLM call](/docs/how_to/summarize_stuff/)
  + [How to use toolkits](/docs/how_to/toolkits/)
  + [How to add ad-hoc tool calling capability to LLMs and Chat Models](/docs/how_to/tools_prompting/)
  + [Build an Agent with AgentExecutor (Legacy)](/docs/how_to/agent_executor/)
  + [How to construct knowledge graphs](/docs/how_to/graph_constructing/)
  + [How to partially format prompt templates](/docs/how_to/prompts_partial/)
  + [How to handle multiple queries when doing query analysis](/docs/how_to/query_multiple_queries/)
  + [How to use built-in tools and toolkits](/docs/how_to/tools_builtin/)
  + [How to pass through arguments from one step to the next](/docs/how_to/passthrough/)
  + [How to compose prompts together](/docs/how_to/prompts_composition/)
  + [How to handle multiple retrievers when doing query analysis](/docs/how_to/query_multiple_retrievers/)
  + [How to add values to a chain's state](/docs/how_to/assign/)
  + [How to construct filters for query analysis](/docs/how_to/query_constructing_filters/)
  + [How to configure runtime chain internals](/docs/how_to/configure/)
  + [How deal with high cardinality categoricals when doing query analysis](/docs/how_to/query_high_cardinality/)
  + [Custom Document Loader](/docs/how_to/document_loader_custom/)
  + [How to use the MultiQueryRetriever](/docs/how_to/MultiQueryRetriever/)
  + [How to add scores to retriever results](/docs/how_to/add_scores_retriever/)
  + [Caching](/docs/how_to/caching_embeddings/)
  + [How to use callbacks in async environments](/docs/how_to/callbacks_async/)
  + [How to attach callbacks to a runnable](/docs/how_to/callbacks_attach/)
  + [How to propagate callbacks constructor](/docs/how_to/callbacks_constructor/)
  + [How to dispatch custom callback events](/docs/how_to/callbacks_custom_events/)
  + [How to pass callbacks in at runtime](/docs/how_to/callbacks_runtime/)
  + [How to split by character](/docs/how_to/character_text_splitter/)
  + [How to cache chat model responses](/docs/how_to/chat_model_caching/)
  + [How to handle rate limits](/docs/how_to/chat_model_rate_limiting/)
  + [How to init any model in one line](/docs/how_to/chat_models_universal_init/)
  + [How to track token usage in ChatModels](/docs/how_to/chat_token_usage_tracking/)
  + [How to add tools to chatbots](/docs/how_to/chatbots_tools/)
  + [How to split code](/docs/how_to/code_splitter/)
  + [How to do retrieval with contextual compression](/docs/how_to/contextual_compression/)
  + [How to convert Runnables to Tools](/docs/how_to/convert_runnable_to_tool/)
  + [How to create custom callback handlers](/docs/how_to/custom_callbacks/)
  + [How to create a custom chat model class](/docs/how_to/custom_chat_model/)
  + [Custom Embeddings](/docs/how_to/custom_embeddings/)
  + [How to create a custom LLM class](/docs/how_to/custom_llm/)
  + [Custom Retriever](/docs/how_to/custom_retriever/)
  + [How to create tools](/docs/how_to/custom_tools/)
  + [How to debug your LLM apps](/docs/how_to/debugging/)
  + [How to load CSVs](/docs/how_to/document_loader_csv/)
  + [How to load documents from a directory](/docs/how_to/document_loader_directory/)
  + [How to load HTML](/docs/how_to/document_loader_html/)
  + [How to load JSON](/docs/how_to/document_loader_json/)
  + [How to load Markdown](/docs/how_to/document_loader_markdown/)
  + [How to load Microsoft Office files](/docs/how_to/document_loader_office_file/)
  + [How to load PDFs](/docs/how_to/document_loader_pdf/)
  + [How to load web pages](/docs/how_to/document_loader_web/)
  + [How to create a dynamic (self-constructing) chain](/docs/how_to/dynamic_chain/)
  + [Text embedding models](/docs/how_to/embed_text/)
  + [How to combine results from multiple retrievers](/docs/how_to/ensemble_retriever/)
  + [How to select examples from a LangSmith dataset](/docs/how_to/example_selectors_langsmith/)
  + [How to select examples by length](/docs/how_to/example_selectors_length_based/)
  + [How to select examples by maximal marginal relevance (MMR)](/docs/how_to/example_selectors_mmr/)
  + [How to select examples by n-gram overlap](/docs/how_to/example_selectors_ngram/)
  + [How to select examples by similarity](/docs/how_to/example_selectors_similarity/)
  + [How to use reference examples when doing extraction](/docs/how_to/extraction_examples/)
  + [How to handle long text when doing extraction](/docs/how_to/extraction_long_text/)
  + [How to use prompting alone (no tool calling) to do extraction](/docs/how_to/extraction_parse/)
  + [How to add fallbacks to a runnable](/docs/how_to/fallbacks/)
  + [How to filter messages](/docs/how_to/filter_messages/)
  + [Hybrid Search](/docs/how_to/hybrid/)
  + [How to use the LangChain indexing API](/docs/how_to/indexing/)
  + [How to inspect runnables](/docs/how_to/inspect/)
  + [LangChain Expression Language Cheatsheet](/docs/how_to/lcel_cheatsheet/)
  + [How to cache LLM responses](/docs/how_to/llm_caching/)
  + [How to track token usage for LLMs](/docs/how_to/llm_token_usage_tracking/)
  + [Run models locally](/docs/how_to/local_llms/)
  + [How to get log probabilities](/docs/how_to/logprobs/)
  + [How to reorder retrieved results to mitigate the "lost in the middle" effect](/docs/how_to/long_context_reorder/)
  + [How to split Markdown by Headers](/docs/how_to/markdown_header_metadata_splitter/)
  + [How to merge consecutive messages of the same type](/docs/how_to/merge_message_runs/)
  + [How to add message history](/docs/how_to/message_history/)
  + [How to migrate from legacy LangChain agents to LangGraph](/docs/how_to/migrate_agent/)
  + [How to retrieve using multiple vectors per document](/docs/how_to/multi_vector/)
  + [How to pass multimodal data directly to models](/docs/how_to/multimodal_inputs/)
  + [How to use multimodal prompts](/docs/how_to/multimodal_prompts/)
  + [How to create a custom Output Parser](/docs/how_to/output_parser_custom/)
  + [How to use the output-fixing parser](/docs/how_to/output_parser_fixing/)
  + [How to parse JSON output](/docs/how_to/output_parser_json/)
  + [How to retry when a parsing error occurs](/docs/how_to/output_parser_retry/)
  + [How to parse text from message objects](/docs/how_to/output_parser_string/)
  + [How to parse XML output](/docs/how_to/output_parser_xml/)
  + [How to parse YAML output](/docs/how_to/output_parser_yaml/)
  + [How to use the Parent Document Retriever](/docs/how_to/parent_document_retriever/)
  + [How to use LangChain with different Pydantic versions](/docs/how_to/pydantic_compatibility/)
  + [How to add chat history](/docs/how_to/qa_chat_history_how_to/)
  + [How to get a RAG application to add citations](/docs/how_to/qa_citations/)
  + [How to do per-user retrieval](/docs/how_to/qa_per_user/)
  + [How to get your RAG application to return sources](/docs/how_to/qa_sources/)
  + [How to stream results from your RAG application](/docs/how_to/qa_streaming/)
  + [How to split JSON data](/docs/how_to/recursive_json_splitter/)
  + [How to recursively split text by characters](/docs/how_to/recursive_text_splitter/)
  + [Response metadata](/docs/how_to/response_metadata/)
  + [How to pass runtime secrets to runnables](/docs/how_to/runnable_runtime_secrets/)
  + [How to do "self-querying" retrieval](/docs/how_to/self_query/)
  + [How to split text based on semantic similarity](/docs/how_to/semantic-chunker/)
  + [How to chain runnables](/docs/how_to/sequence/)
  + [How to save and load LangChain objects](/docs/how_to/serialization/)
  + [How to split text by tokens](/docs/how_to/split_by_token/)
  + [How to split HTML](/docs/how_to/split_html/)
  + [How to do question answering over CSVs](/docs/how_to/sql_csv/)
  + [How to deal with large databases when doing SQL question-answering](/docs/how_to/sql_large_db/)
  + [How to better prompt when doing SQL question-answering](/docs/how_to/sql_prompting/)
  + [How to do query validation as part of SQL question-answering](/docs/how_to/sql_query_checking/)
  + [How to stream runnables](/docs/how_to/streaming/)
  + [How to stream responses from an LLM](/docs/how_to/streaming_llm/)
  + [How to use a time-weighted vector store retriever](/docs/how_to/time_weighted_vectorstore/)
  + [How to return artifacts from a tool](/docs/how_to/tool_artifacts/)
  + [How to use chat models to call tools](/docs/how_to/tool_calling/)
  + [How to disable parallel tool calling](/docs/how_to/tool_calling_parallel/)
  + [How to force models to call a tool](/docs/how_to/tool_choice/)
  + [How to access the RunnableConfig from a tool](/docs/how_to/tool_configure/)
  + [How to pass tool outputs to chat models](/docs/how_to/tool_results_pass_to_model/)
  + [How to pass run time values to tools](/docs/how_to/tool_runtime/)
  + [How to stream events from a tool](/docs/how_to/tool_stream_events/)
  + [How to stream tool calls](/docs/how_to/tool_streaming/)
  + [How to convert tools to OpenAI Functions](/docs/how_to/tools_as_openai_functions/)
  + [How to handle tool errors](/docs/how_to/tools_error/)
  + [How to use few-shot prompting with tool calling](/docs/how_to/tools_few_shot/)
  + [How to add a human-in-the-loop for tools](/docs/how_to/tools_human/)
  + [How to bind model-specific tools](/docs/how_to/tools_model_specific/)
  + [How to trim messages](/docs/how_to/trim_messages/)
  + [How to create and query vector stores](/docs/how_to/vectorstores/)
* [Conceptual guide](/docs/concepts/)
  + [Agents](/docs/concepts/agents/)
  + [Architecture](/docs/concepts/architecture/)
  + [Async programming with langchain](/docs/concepts/async/)
  + [Callbacks](/docs/concepts/callbacks/)
  + [Chat history](/docs/concepts/chat_history/)
  + [Chat models](/docs/concepts/chat_models/)
  + [Document loaders](/docs/concepts/document_loaders/)
  + [Embedding models](/docs/concepts/embedding_models/)
  + [Evaluation](/docs/concepts/evaluation/)
  + [Example selectors](/docs/concepts/example_selectors/)
  + [Few-shot prompting](/docs/concepts/few_shot_prompting/)
  + [Conceptual guide](/docs/concepts/)
  + [Key-value stores](/docs/concepts/key_value_stores/)
  + [LangChain Expression Language (LCEL)](/docs/concepts/lcel/)
  + [Messages](/docs/concepts/messages/)
  + [Multimodality](/docs/concepts/multimodality/)
  + [Output parsers](/docs/concepts/output_parsers/)
  + [Prompt Templates](/docs/concepts/prompt_templates/)
  + [Retrieval augmented generation (RAG)](/docs/concepts/rag/)
  + [Retrieval](/docs/concepts/retrieval/)
  + [Retrievers](/docs/concepts/retrievers/)
  + [Runnable interface](/docs/concepts/runnables/)
  + [Streaming](/docs/concepts/streaming/)
  + [Structured outputs](/docs/concepts/structured_outputs/)
  + [Testing](/docs/concepts/testing/)
  + [String-in, string-out llms](/docs/concepts/text_llms/)
  + [Text splitters](/docs/concepts/text_splitters/)
  + [Tokens](/docs/concepts/tokens/)
  + [Tool calling](/docs/concepts/tool_calling/)
  + [Tools](/docs/concepts/tools/)
  + [Tracing](/docs/concepts/tracing/)
  + [Vector stores](/docs/concepts/vectorstores/)
  + [Why LangChain?](/docs/concepts/why_langchain/)
* Ecosystem
  + [ü¶úüõ†Ô∏è LangSmith](https://docs.smith.langchain.com/)
  + [ü¶úüï∏Ô∏è LangGraph](https://langchain-ai.github.io/langgraph/)
* Versions
  + [v0.3](/docs/versions/v0_3/)
  + [v0.2](/docs/versions/v0_2/overview/)
    - [Overview](/docs/versions/v0_2/overview/)
    - [Migration](/docs/versions/v0_2/)
    - [astream\_events v2](/docs/versions/v0_2/migrating_astream_events/)
    - [Changes](/docs/versions/v0_2/deprecations/)
  + [Pydantic compatibility](/docs/how_to/pydantic_compatibility/)
  + [Migrating from v0.0 chains](/docs/versions/migrating_chains/)
    - [How to migrate from v0.0 chains](/docs/versions/migrating_chains/)
    - [Migrating from ConstitutionalChain](/docs/versions/migrating_chains/constitutional_chain/)
    - [Migrating from ConversationalChain](/docs/versions/migrating_chains/conversation_chain/)
    - [Migrating from ConversationalRetrievalChain](/docs/versions/migrating_chains/conversation_retrieval_chain/)
    - [Migrating from LLMChain](/docs/versions/migrating_chains/llm_chain/)
    - [Migrating from LLMMathChain](/docs/versions/migrating_chains/llm_math_chain/)
    - [Migrating from LLMRouterChain](/docs/versions/migrating_chains/llm_router_chain/)
    - [Migrating from MapReduceDocumentsChain](/docs/versions/migrating_chains/map_reduce_chain/)
    - [Migrating from MapRerankDocumentsChain](/docs/versions/migrating_chains/map_rerank_docs_chain/)
    - [Migrating from MultiPromptChain](/docs/versions/migrating_chains/multi_prompt_chain/)
    - [Migrating from RefineDocumentsChain](/docs/versions/migrating_chains/refine_docs_chain/)
    - [Migrating from RetrievalQA](/docs/versions/migrating_chains/retrieval_qa/)
    - [Migrating from StuffDocumentsChain](/docs/versions/migrating_chains/stuff_docs_chain/)
  + [Upgrading to LangGraph memory](/docs/versions/migrating_memory/)
    - [How to migrate to LangGraph memory](/docs/versions/migrating_memory/)
    - [How to use BaseChatMessageHistory with LangGraph](/docs/versions/migrating_memory/chat_history/)
    - [Migrating off ConversationBufferMemory or ConversationStringBufferMemory](/docs/versions/migrating_memory/conversation_buffer_memory/)
    - [Migrating off ConversationBufferWindowMemory or ConversationTokenBufferMemory](/docs/versions/migrating_memory/conversation_buffer_window_memory/)
    - [Migrating off ConversationSummaryMemory or ConversationSummaryBufferMemory](/docs/versions/migrating_memory/conversation_summary_memory/)
    - [A Long-Term Memory Agent](/docs/versions/migrating_memory/long_term_memory_agent/)
  + [Release policy](/docs/versions/release_policy/)
* [Security Policy](/docs/security/)


* Versions
* v0.2
* astream\_events v2
On this page[![](https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github&logoColor=white)](https://github.com/langchain-ai/langchain/blob/master/docs/docs/versions/v0_2/migrating_astream_events.mdx)

Migrating to astream\_events(..., version="v2")
===============================================

We've added a `v2` of the astream\_events API with the release of `0.2.x`. You can see this [PR](https://github.com/langchain-ai/langchain/pull/21638) for more details.

The `v2` version is a re-write of the `v1` version, and should be more efficient, with more consistent output for the events. The `v1` version of the API will be deprecated in favor of the `v2` version and will be removed in `0.4.0`.

Below is a list of changes between the `v1` and `v2` versions of the API.

### output for `on_chat_model_end`[‚Äã](#output-for-on_chat_model_end)

In `v1`, the outputs associated with `on_chat_model_end` changed depending on whether the chat model was run as a root level runnable or as part of a chain.

As a root level runnable the output was:

```
"data":{"output": AIMessageChunk(content="hello world!",id='some id')}  

```

As part of a chain the output was:

```
 "data": {  
 "output": {  
 "generations": [  
 [  
 {  
 "generation_info": None,  
 "message": AIMessageChunk(  
 content="hello world!", id=AnyStr()  
 ),  
 "text": "hello world!",  
 "type": "ChatGenerationChunk",  
 }  
 ]  
 ],  
 "llm_output": None,  
 }  
 },  

```

As of `v2`, the output will always be the simpler representation:

```
"data":{"output": AIMessageChunk(content="hello world!",id='some id')}  

```
note

Non chat models (i.e., regular LLMs) are will be consistently associated with the more verbose format for now.

### output for `on_retriever_end`[‚Äã](#output-for-on_retriever_end)

`on_retriever_end` output will always return a list of `Documents`.

Before:

```
{  
"data":{  
"output":[  
 Document(...),  
 Document(...),  
...  
]  
}  
}  

```
### Removed `on_retriever_stream`[‚Äã](#removed-on_retriever_stream)

The `on_retriever_stream` event was an artifact of the implementation and has been removed.

Full information associated with the event is already available in the `on_retriever_end` event.

Please use `on_retriever_end` instead.

### Removed `on_tool_stream`[‚Äã](#removed-on_tool_stream)

The `on_tool_stream` event was an artifact of the implementation and has been removed.

Full information associated with the event is already available in the `on_tool_end` event.

Please use `on_tool_end` instead.

### Propagating Names[‚Äã](#propagating-names)

Names of runnables have been updated to be more consistent.

```
model = GenericFakeChatModel(messages=infinite_cycle).configurable_fields(  
 messages=ConfigurableField(  
id="messages",  
 name="Messages",  
 description="Messages return by the LLM",  
)  
)  

```

In `v1`, the event name was `RunnableConfigurableFields`.

In `v2`, the event name is `GenericFakeChatModel`.

If you're filtering by event names, check if you need to update your filters.

### RunnableRetry[‚Äã](#runnableretry)

Usage of [RunnableRetry](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.retry.RunnableRetry.html) within an LCEL chain being streamed generated an incorrect `on_chain_end` event in `v1` corresponding to the failed runnable invocation that was being retried. This event has been removed in `v2`.

No action is required for this change.

[Edit this page](https://github.com/langchain-ai/langchain/edit/master/docs/docs/versions/v0_2/migrating_astream_events.mdx)

---

#### Was this page helpful?

[PreviousMigration](/docs/versions/v0_2/)[NextChanges](/docs/versions/v0_2/deprecations/)

* [output for `on_chat_model_end`](#output-for-on_chat_model_end)
* [output for `on_retriever_end`](#output-for-on_retriever_end)
* [Removed `on_retriever_stream`](#removed-on_retriever_stream)
* [Removed `on_tool_stream`](#removed-on_tool_stream)
* [Propagating Names](#propagating-names)
* [RunnableRetry](#runnableretry)
Community

* [Twitter](https://twitter.com/LangChainAI)
GitHub

* [Organization](https://github.com/langchain-ai)
* [Python](https://github.com/langchain-ai/langchain)
* [JS/TS](https://github.com/langchain-ai/langchainjs)
More

* [Homepage](https://langchain.com)
* [Blog](https://blog.langchain.dev)
* [YouTube](https://www.youtube.com/@LangChain)
Copyright ¬© 2024 LangChain, Inc.